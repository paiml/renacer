<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>ML Pipeline with EXTREME TDD - The Renacer Book - Pure Rust System Call Tracing</title>


        <!-- Custom HTML head -->

        <meta name="description" content="A comprehensive guide to renacer: syscall tracing, DWARF correlation, and performance analysis">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Renacer Book - Pure Rust System Call Tracing</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/renacer" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/renacer/edit/main/book/src/advanced/ml-pipeline.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="ml-pipeline-with-extreme-tdd"><a class="header" href="#ml-pipeline-with-extreme-tdd">ML Pipeline with EXTREME TDD</a></h1>
<p>This chapter demonstrates implementing renacer's Sprint 48 ML Pipeline using EXTREME TDD methodology: RED-GREEN-REFACTOR cycles, property-based testing, and Toyota Way principles.</p>
<blockquote>
<p><strong>EXTREME TDD-Verified:</strong> All code in this chapter developed test-first in <a href="../../../src/ml_pipeline.rs"><code>src/ml_pipeline.rs</code></a> and <a href="../../../src/model_persistence.rs"><code>src/model_persistence.rs</code></a></p>
</blockquote>
<h2 id="toyota-way-foundations"><a class="header" href="#toyota-way-foundations">Toyota Way Foundations</a></h2>
<p>The ML Pipeline embodies three Toyota Way principles:</p>
<div class="table-wrapper"><table><thead><tr><th>Principle</th><th>Japanese</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>Muda</strong></td><td>無駄</td><td>Eliminate waste: persist models instead of retraining</td></tr>
<tr><td><strong>Kaizen</strong></td><td>改善</td><td>Continuous improvement via standardized preprocessing</td></tr>
<tr><td><strong>Poka-yoke</strong></td><td>ポカヨケ</td><td>Error-proofing through type-safe APIs</td></tr>
</tbody></table>
</div>
<h2 id="architecture-overview"><a class="header" href="#architecture-overview">Architecture Overview</a></h2>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│                    renacer ML Pipeline                          │
├─────────────────────────────────────────────────────────────────┤
│  Syscall Data (HashMap&lt;String, (u64, u64)&gt;)                     │
│           │                                                      │
│           ▼                                                      │
│  ┌─────────────────┐                                            │
│  │ extract_features│  → Matrix&lt;f32&gt; (n_samples × 3 features)    │
│  └────────┬────────┘                                            │
│           │                                                      │
│           ▼                                                      │
│  ┌─────────────────┐                                            │
│  │normalize_features│ → NormalizedFeatures (StandardScaler)     │
│  └────────┬────────┘                                            │
│           │                                                      │
│           ├──────────────┬──────────────┬──────────────┐        │
│           ▼              ▼              ▼              ▼        │
│    ┌──────────┐   ┌───────────┐   ┌─────────┐   ┌──────────┐   │
│    │run_dbscan│   │  run_lof  │   │ run_pca │   │find_opt_k│   │
│    └──────────┘   └───────────┘   └─────────┘   └──────────┘   │
│           │              │              │              │        │
│           ▼              ▼              ▼              ▼        │
│    DBSCANResult   LOFResult      PCAResult     optimal_k       │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h2 id="extreme-tdd-workflow"><a class="header" href="#extreme-tdd-workflow">EXTREME TDD Workflow</a></h2>
<h3 id="phase-1-red---write-failing-tests-first"><a class="header" href="#phase-1-red---write-failing-tests-first">Phase 1: RED - Write Failing Tests First</a></h3>
<p>Before writing any implementation, we define the expected behavior:</p>
<pre><code class="language-rust">// RED: This test will fail - no implementation exists yet
#[test]
fn test_extract_features_basic() {
    let mut data = HashMap::new();
    data.insert("write".to_string(), (100, 1_000_000)); // 10µs avg
    data.insert("read".to_string(), (50, 500_000));     // 10µs avg

    let (names, features) = extract_features(&amp;data).unwrap();

    assert_eq!(names.len(), 2);
    let (rows, cols) = features.shape();
    assert_eq!(rows, 2);
    assert_eq!(cols, 3); // 3 features per syscall
}</code></pre>
<p><strong>Why 3 features?</strong> We extract:</p>
<ol>
<li><code>avg_duration</code> - Average syscall duration in microseconds</li>
<li><code>log_count</code> - Log-scaled call count (handles large ranges)</li>
<li><code>log_total_duration</code> - Log-scaled total time spent</li>
</ol>
<h3 id="phase-2-green---minimal-implementation"><a class="header" href="#phase-2-green---minimal-implementation">Phase 2: GREEN - Minimal Implementation</a></h3>
<pre><code class="language-rust">pub fn extract_features(
    syscall_data: &amp;HashMap&lt;String, (u64, u64)&gt;,
) -&gt; Result&lt;(Vec&lt;String&gt;, Matrix&lt;f32&gt;)&gt; {
    let mut syscall_names = Vec::new();
    let mut features_data = Vec::new();

    for (name, (count, total_time_ns)) in syscall_data {
        if *count == 0 { continue; }

        let total_time_us = *total_time_ns as f64 / 1000.0;
        let avg_time_us = total_time_us / *count as f64;

        syscall_names.push(name.clone());

        // Feature vector: [avg_duration, log(count), log(total_duration)]
        features_data.push(avg_time_us as f32);
        features_data.push((*count as f32).ln().max(0.0));
        features_data.push((total_time_us as f32).ln().max(0.0));
    }

    let n_samples = syscall_names.len();
    if n_samples &lt; 2 {
        return Err(PipelineError::InsufficientData {
            required: 2,
            actual: n_samples,
        });
    }

    let matrix = Matrix::from_vec(n_samples, 3, features_data)
        .map_err(|e| PipelineError::FeatureExtractionError(e.to_string()))?;

    Ok((syscall_names, matrix))
}</code></pre>
<h3 id="phase-3-refactor---add-edge-case-tests"><a class="header" href="#phase-3-refactor---add-edge-case-tests">Phase 3: REFACTOR - Add Edge Case Tests</a></h3>
<pre><code class="language-rust">#[test]
fn test_extract_features_insufficient_data() {
    let mut data = HashMap::new();
    data.insert("write".to_string(), (100, 1_000_000));
    // Only 1 syscall - not enough for clustering!

    let result = extract_features(&amp;data);
    assert!(matches!(result, Err(PipelineError::InsufficientData { .. })));
}

#[test]
fn test_extract_features_skips_zero_count() {
    let mut data = HashMap::new();
    data.insert("write".to_string(), (100, 1_000_000));
    data.insert("read".to_string(), (50, 500_000));
    data.insert("empty".to_string(), (0, 0)); // Should be skipped

    let (names, _) = extract_features(&amp;data).unwrap();
    assert_eq!(names.len(), 2);
    assert!(!names.contains(&amp;"empty".to_string()));
}</code></pre>
<h2 id="feature-normalization-with-standardscaler"><a class="header" href="#feature-normalization-with-standardscaler">Feature Normalization with StandardScaler</a></h2>
<h3 id="red-define-expected-behavior"><a class="header" href="#red-define-expected-behavior">RED: Define Expected Behavior</a></h3>
<pre><code class="language-rust">#[test]
fn test_normalize_features_zero_mean() {
    let mut data = HashMap::new();
    data.insert("write".to_string(), (100, 1_000_000));
    data.insert("read".to_string(), (50, 500_000));
    data.insert("openat".to_string(), (20, 200_000));

    let (names, features) = extract_features(&amp;data).unwrap();
    let normalized = normalize_features(names, features).unwrap();

    // After normalization, mean of each column should be ~0
    let (n_rows, n_cols) = normalized.data.shape();
    for j in 0..n_cols {
        let sum: f32 = (0..n_rows).map(|i| normalized.data.get(i, j)).sum();
        let mean = sum / n_rows as f32;
        assert!(mean.abs() &lt; 0.01, "Column {} mean should be ~0, got {}", j, mean);
    }
}</code></pre>
<h3 id="green-implementation"><a class="header" href="#green-implementation">GREEN: Implementation</a></h3>
<pre><code class="language-rust">use aprender::preprocessing::StandardScaler;
use aprender::traits::{Transformer, UnsupervisedEstimator};

pub fn normalize_features(
    syscall_names: Vec&lt;String&gt;,
    features: Matrix&lt;f32&gt;,
) -&gt; Result&lt;NormalizedFeatures&gt; {
    let mut scaler = StandardScaler::new()
        .with_mean(true)
        .with_std(true);

    scaler.fit(&amp;features)
        .map_err(|e| PipelineError::PreprocessingError(e.to_string()))?;

    let normalized = scaler.transform(&amp;features)
        .map_err(|e| PipelineError::PreprocessingError(e.to_string()))?;

    Ok(NormalizedFeatures {
        data: normalized,
        syscall_names,
        feature_names: vec![
            "avg_duration".to_string(),
            "log_count".to_string(),
            "log_total_duration".to_string(),
        ],
        means: scaler.mean().to_vec(),
        stds: scaler.std().to_vec(),
    })
}</code></pre>
<h2 id="dbscan-clustering"><a class="header" href="#dbscan-clustering">DBSCAN Clustering</a></h2>
<p>DBSCAN (Density-Based Spatial Clustering of Applications with Noise) identifies anomalies as <strong>noise points</strong> (label = -1).</p>
<h3 id="red-test-cluster-detection"><a class="header" href="#red-test-cluster-detection">RED: Test Cluster Detection</a></h3>
<pre><code class="language-rust">#[test]
fn test_dbscan_finds_clusters() {
    let mut data = HashMap::new();
    // Group 1: fast syscalls
    data.insert("write".to_string(), (1000, 10_000_000));  // 10µs avg
    data.insert("read".to_string(), (1000, 10_000_000));   // 10µs avg
    // Group 2: slow syscalls
    data.insert("mmap".to_string(), (100, 100_000_000));   // 1000µs avg
    data.insert("munmap".to_string(), (100, 100_000_000)); // 1000µs avg

    let (names, features) = extract_features(&amp;data).unwrap();
    let normalized = normalize_features(names, features).unwrap();

    let result = run_dbscan(&amp;normalized, 1.0, 2).unwrap();

    assert!(result.n_clusters &gt;= 1);
    assert_eq!(result.syscall_names.len(), 4);
}</code></pre>
<h3 id="red-test-noise-detection-anomalies"><a class="header" href="#red-test-noise-detection-anomalies">RED: Test Noise Detection (Anomalies)</a></h3>
<pre><code class="language-rust">#[test]
fn test_dbscan_identifies_noise() {
    let mut data = HashMap::new();
    // Normal syscalls (cluster together)
    data.insert("write".to_string(), (1000, 10_000_000));
    data.insert("read".to_string(), (1000, 10_000_000));
    data.insert("close".to_string(), (1000, 10_000_000));
    // Outlier (will be noise)
    data.insert("slow_syscall".to_string(), (10, 1_000_000_000)); // 100ms avg!

    let (names, features) = extract_features(&amp;data).unwrap();
    let normalized = normalize_features(names, features).unwrap();

    let result = run_dbscan(&amp;normalized, 0.5, 2).unwrap();

    // Should have noise points (anomalies)
    assert!(result.n_noise &gt; 0 || result.n_clusters &gt; 1);
}</code></pre>
<h3 id="green-implementation-1"><a class="header" href="#green-implementation-1">GREEN: Implementation</a></h3>
<pre><code class="language-rust">use aprender::cluster::DBSCAN;

pub fn run_dbscan(
    features: &amp;NormalizedFeatures,
    eps: f32,
    min_samples: usize,
) -&gt; Result&lt;DBSCANResult&gt; {
    let mut dbscan = DBSCAN::new(eps, min_samples);

    dbscan.fit(&amp;features.data)
        .map_err(|e| PipelineError::ClusteringError(e.to_string()))?;

    let labels = dbscan.labels().clone();

    // Count clusters and noise
    let n_noise = labels.iter().filter(|&amp;&amp;l| l == -1).count();
    let n_clusters = labels.iter()
        .filter(|&amp;&amp;l| l &gt;= 0)
        .collect::&lt;HashSet&lt;_&gt;&gt;()
        .len();

    // Calculate silhouette score if we have enough clusters
    let silhouette = calculate_silhouette(&amp;features.data, &amp;labels);

    Ok(DBSCANResult {
        labels,
        n_clusters,
        n_noise,
        syscall_names: features.syscall_names.clone(),
        silhouette,
    })
}</code></pre>
<h2 id="local-outlier-factor-lof"><a class="header" href="#local-outlier-factor-lof">Local Outlier Factor (LOF)</a></h2>
<p>LOF detects anomalies based on local density deviation. Syscalls with significantly lower density than neighbors are outliers.</p>
<h3 id="red-test-outlier-detection"><a class="header" href="#red-test-outlier-detection">RED: Test Outlier Detection</a></h3>
<pre><code class="language-rust">#[test]
fn test_lof_detects_outliers() {
    let mut data = HashMap::new();
    // Normal syscalls
    data.insert("write".to_string(), (1000, 10_000_000));
    data.insert("read".to_string(), (1000, 10_000_000));
    data.insert("close".to_string(), (1000, 10_000_000));
    // Outlier
    data.insert("slow_syscall".to_string(), (10, 1_000_000_000));

    let (names, features) = extract_features(&amp;data).unwrap();
    let normalized = normalize_features(names, features).unwrap();

    let result = run_lof(&amp;normalized, &amp;data, 2, 0.25).unwrap();

    // Should detect outliers
    assert!(!result.outliers.is_empty() || result.labels.iter().any(|&amp;l| l == -1));
    assert_eq!(result.scores.len(), 4);
}</code></pre>
<h3 id="green-implementation-2"><a class="header" href="#green-implementation-2">GREEN: Implementation</a></h3>
<pre><code class="language-rust">use aprender::cluster::LocalOutlierFactor;

pub fn run_lof(
    features: &amp;NormalizedFeatures,
    syscall_data: &amp;HashMap&lt;String, (u64, u64)&gt;,
    n_neighbors: usize,
    contamination: f32,
) -&gt; Result&lt;LOFResult&gt; {
    let mut lof = LocalOutlierFactor::new()
        .with_n_neighbors(n_neighbors)
        .with_contamination(contamination);

    lof.fit(&amp;features.data)
        .map_err(|e| PipelineError::ClusteringError(e.to_string()))?;

    let labels = lof.predict(&amp;features.data);
    let scores = lof.score_samples(&amp;features.data);

    // Build outlier info
    let mut outliers = Vec::new();
    for (i, (&amp;label, &amp;score)) in labels.iter().zip(scores.iter()).enumerate() {
        if label == -1 {
            let syscall = &amp;features.syscall_names[i];
            let (count, total_ns) = syscall_data.get(syscall).copied().unwrap_or((0, 0));
            let avg_time_us = if count &gt; 0 {
                (total_ns as f64 / 1000.0) / count as f64
            } else { 0.0 };

            outliers.push(OutlierInfo {
                syscall: syscall.clone(),
                lof_score: score,
                avg_time_us,
                call_count: count,
            });
        }
    }

    // Sort by LOF score (highest = most anomalous)
    outliers.sort_by(|a, b| b.lof_score.partial_cmp(&amp;a.lof_score).unwrap_or(Ordering::Equal));

    Ok(LOFResult { labels, scores, syscall_names: features.syscall_names.clone(), outliers })
}</code></pre>
<h2 id="silhouette-score-for-cluster-quality"><a class="header" href="#silhouette-score-for-cluster-quality">Silhouette Score for Cluster Quality</a></h2>
<p>Silhouette score measures clustering quality: -1 (worst) to 1 (best).</p>
<h3 id="red-test-well-separated-clusters"><a class="header" href="#red-test-well-separated-clusters">RED: Test Well-Separated Clusters</a></h3>
<pre><code class="language-rust">#[test]
fn test_silhouette_score_well_separated() {
    // Two perfectly separated clusters
    let data = vec![
        1.0, 1.0,   // Cluster 0
        1.1, 1.1,   // Cluster 0
        10.0, 10.0, // Cluster 1
        10.1, 10.1, // Cluster 1
    ];
    let matrix = Matrix::from_vec(4, 2, data).unwrap();
    let labels = vec![0, 0, 1, 1];

    let score = calculate_silhouette(&amp;matrix, &amp;labels);

    assert!(score.is_some());
    let s = score.unwrap();
    assert!(s &gt; 0.8, "Well-separated clusters should have high silhouette, got {}", s);
}</code></pre>
<h3 id="red-edge-case---single-cluster"><a class="header" href="#red-edge-case---single-cluster">RED: Edge Case - Single Cluster</a></h3>
<pre><code class="language-rust">#[test]
fn test_silhouette_score_single_cluster() {
    let data = vec![1.0, 1.0, 1.1, 1.1, 1.2, 1.2];
    let matrix = Matrix::from_vec(3, 2, data).unwrap();
    let labels = vec![0, 0, 0]; // Single cluster

    let score = calculate_silhouette(&amp;matrix, &amp;labels);
    assert!(score.is_none()); // Need at least 2 clusters
}</code></pre>
<h2 id="pca-dimensionality-reduction"><a class="header" href="#pca-dimensionality-reduction">PCA Dimensionality Reduction</a></h2>
<p>PCA reduces feature dimensions while preserving variance - useful for visualization.</p>
<h3 id="red-test-dimension-reduction"><a class="header" href="#red-test-dimension-reduction">RED: Test Dimension Reduction</a></h3>
<pre><code class="language-rust">#[test]
fn test_pca_reduces_dimensions() {
    let mut data = HashMap::new();
    data.insert("write".to_string(), (1000, 10_000_000));
    data.insert("read".to_string(), (1000, 10_000_000));
    data.insert("close".to_string(), (1000, 10_000_000));
    data.insert("openat".to_string(), (500, 5_000_000));

    let (names, features) = extract_features(&amp;data).unwrap();
    let normalized = normalize_features(names, features).unwrap();

    let result = run_pca(&amp;normalized, 2).unwrap();

    let (n_samples, n_components) = result.reduced_data.shape();
    assert_eq!(n_samples, 4);
    assert_eq!(n_components, 2); // Reduced from 3 to 2
}</code></pre>
<h3 id="red-test-variance-explained"><a class="header" href="#red-test-variance-explained">RED: Test Variance Explained</a></h3>
<pre><code class="language-rust">#[test]
fn test_pca_variance_explained() {
    // ... setup ...
    let result = run_pca(&amp;normalized, 3).unwrap();

    // Total variance should be &lt;= 1.0
    assert!(result.total_variance_explained &lt;= 1.01,
        "Total variance {} should be &lt;= 1.0", result.total_variance_explained);
}</code></pre>
<h2 id="model-persistence-eliminating-muda"><a class="header" href="#model-persistence-eliminating-muda">Model Persistence: Eliminating MUDA</a></h2>
<p>The <code>.apr</code> format persists trained models, eliminating the waste of retraining.</p>
<h3 id="red-test-saveload-roundtrip"><a class="header" href="#red-test-saveload-roundtrip">RED: Test Save/Load Roundtrip</a></h3>
<pre><code class="language-rust">#[test]
fn test_save_and_load_kmeans_model() {
    let temp_dir = TempDir::new().unwrap();
    let model_path = temp_dir.path().join("test_kmeans.apr");

    let model = SerializableKMeansModel {
        centroids: vec![
            vec![1.0, 2.0, 3.0],
            vec![4.0, 5.0, 6.0],
            vec![7.0, 8.0, 9.0],
        ],
        n_clusters: 3,
        n_features: 3,
        metadata: ModelMetadata::new(1000)
            .with_hyperparameter("n_clusters", "3")
            .with_description("Test KMeans model"),
    };

    // Save
    let options = PersistenceOptions::new()
        .with_name("test-kmeans")
        .with_description("Test model");
    save_kmeans_model(&amp;model, &amp;model_path, options).expect("Failed to save");

    // Load
    let loaded = load_kmeans_model(&amp;model_path).expect("Failed to load");

    assert_eq!(loaded.n_clusters, model.n_clusters);
    assert_eq!(loaded.n_features, model.n_features);
    for (orig, loaded_c) in model.centroids.iter().zip(loaded.centroids.iter()) {
        for (o, l) in orig.iter().zip(loaded_c.iter()) {
            assert!((o - l).abs() &lt; 1e-6);
        }
    }
}</code></pre>
<h3 id="green-implementation-3"><a class="header" href="#green-implementation-3">GREEN: Implementation</a></h3>
<pre><code class="language-rust">use aprender::format::{save, load, Compression, ModelType, SaveOptions};

pub fn save_kmeans_model(
    model: &amp;SerializableKMeansModel,
    path: impl AsRef&lt;Path&gt;,
    options: PersistenceOptions,
) -&gt; Result&lt;()&gt; {
    let compression = if options.compress {
        Compression::ZstdDefault
    } else {
        Compression::None
    };

    let mut save_options = SaveOptions::new().with_compression(compression);
    if let Some(name) = options.name {
        save_options = save_options.with_name(name);
    }

    save(model, ModelType::KMeans, path.as_ref(), save_options)
        .map_err(|e| ModelPersistenceError::SaveError(e.to_string()))
}</code></pre>
<h2 id="property-based-testing"><a class="header" href="#property-based-testing">Property-Based Testing</a></h2>
<p>Property tests verify invariants across random inputs:</p>
<pre><code class="language-rust">#[test]
fn test_normalization_preserves_sample_count() {
    proptest::proptest!(|(n_syscalls in 3usize..10)| {
        let mut data = HashMap::new();
        for i in 0..n_syscalls {
            data.insert(
                format!("syscall_{}", i),
                ((i + 1) as u64 * 100, (i + 1) as u64 * 1_000_000)
            );
        }

        let (names, features) = extract_features(&amp;data).unwrap();
        let normalized = normalize_features(names.clone(), features).unwrap();

        // PROPERTY: Sample count never changes through normalization
        prop_assert_eq!(normalized.syscall_names.len(), names.len());
    });
}

#[test]
fn test_silhouette_bounds() {
    // PROPERTY: Silhouette score always in [-1, 1]
    let data = vec![1.0, 2.0, 3.0, 4.0, 10.0, 20.0, 30.0, 40.0];
    let matrix = Matrix::from_vec(4, 2, data).unwrap();
    let labels = vec![0, 0, 1, 1];

    if let Some(score) = calculate_silhouette(&amp;matrix, &amp;labels) {
        assert!(score &gt;= -1.0 &amp;&amp; score &lt;= 1.0);
    }
}

#[test]
fn test_roundtrip_preserves_centroids() {
    proptest::proptest!(|(n_clusters in 1usize..10, n_features in 1usize..5)| {
        let temp_dir = TempDir::new().unwrap();
        let model_path = temp_dir.path().join("proptest.apr");

        let centroids: Vec&lt;Vec&lt;f32&gt;&gt; = (0..n_clusters)
            .map(|i| (0..n_features).map(|j| (i * n_features + j) as f32).collect())
            .collect();

        let model = SerializableKMeansModel {
            centroids: centroids.clone(),
            n_clusters,
            n_features,
            metadata: ModelMetadata::new(100),
        };

        save_kmeans_model(&amp;model, &amp;model_path, PersistenceOptions::new()).unwrap();
        let loaded = load_kmeans_model(&amp;model_path).unwrap();

        // PROPERTY: Centroids survive roundtrip exactly
        prop_assert_eq!(loaded.centroids.len(), centroids.len());
    });
}</code></pre>
<h2 id="cli-integration"><a class="header" href="#cli-integration">CLI Integration</a></h2>
<h3 id="save-trained-model"><a class="header" href="#save-trained-model">Save Trained Model</a></h3>
<pre><code class="language-bash"># Train and save model
renacer -c --ml-anomaly --save-model baseline.apr -- cargo build

# Output:
# Model saved to baseline.apr (1.2 KB)
# Training samples: 47 syscalls
# Silhouette score: 0.823
</code></pre>
<p><strong>Tested by:</strong> <code>test_save_model_flag_accepted</code></p>
<h3 id="load-pre-trained-model-muda-elimination"><a class="header" href="#load-pre-trained-model-muda-elimination">Load Pre-trained Model (MUDA Elimination)</a></h3>
<pre><code class="language-bash"># Use saved model - no retraining!
renacer -c --ml-anomaly --load-model baseline.apr -- cargo build

# Output:
# Loaded model: baseline.apr (renacer v0.6.3, 47 samples)
# Anomalies detected: 2
</code></pre>
<p><strong>Tested by:</strong> <code>test_load_model_flag_accepted</code></p>
<h3 id="regression-detection"><a class="header" href="#regression-detection">Regression Detection</a></h3>
<pre><code class="language-bash"># Compare against baseline
renacer -c --ml-anomaly --baseline baseline.apr -- cargo build

# Output:
# === Regression Analysis ===
# Baseline: 47 syscalls, 823ms total
# Current:  52 syscalls, 1247ms total (+51%)
#
# New anomalies not in baseline:
#   - futex (424ms avg) - REGRESSION
</code></pre>
<p><strong>Tested by:</strong> <code>test_baseline_flag_accepted</code></p>
<h2 id="example-finding-performance-regressions"><a class="header" href="#example-finding-performance-regressions">Example: Finding Performance Regressions</a></h2>
<pre><code class="language-bash"># Step 1: Capture baseline
$ renacer -c --ml-anomaly --save-model release-1.0.apr -- ./my-app
Model saved: release-1.0.apr (47 syscalls, silhouette: 0.85)

# Step 2: After code changes, compare
$ renacer -c --ml-anomaly --baseline release-1.0.apr -- ./my-app

=== DBSCAN Clustering Results ===
Clusters found: 3
Noise points (potential anomalies): 2

Noise/anomaly syscalls:
  - futex (NEW - not in baseline!)
  - mmap

=== Local Outlier Factor Analysis ===
Outliers detected: 2
  - futex (LOF: 4.23, avg: 1250µs, calls: 847) - REGRESSION
  - mmap (LOF: 2.15, avg: 523µs, calls: 12)

=== Regression Summary ===
Baseline silhouette: 0.85
Current silhouette:  0.67 (-21%)
New syscalls: futex
Recommendation: Investigate futex contention
</code></pre>
<h2 id="performance-characteristics"><a class="header" href="#performance-characteristics">Performance Characteristics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Operation</th><th>Complexity</th><th>Typical Time</th></tr></thead><tbody>
<tr><td>Feature extraction</td><td>O(n)</td><td>&lt;1ms for 100 syscalls</td></tr>
<tr><td>StandardScaler</td><td>O(n×d)</td><td>&lt;1ms</td></tr>
<tr><td>DBSCAN</td><td>O(n²)</td><td>~10ms for 100 syscalls</td></tr>
<tr><td>LOF</td><td>O(n×k)</td><td>~5ms for 100 syscalls</td></tr>
<tr><td>PCA</td><td>O(n×d²)</td><td>&lt;1ms</td></tr>
<tr><td>Model save</td><td>O(centroids)</td><td>~1ms</td></tr>
<tr><td>Model load</td><td>O(centroids)</td><td>~1ms</td></tr>
</tbody></table>
</div>
<p><strong>Zero overhead when ML disabled</strong> - all analysis is opt-in.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The ML Pipeline demonstrates EXTREME TDD principles:</p>
<div class="table-wrapper"><table><thead><tr><th>Phase</th><th>What We Did</th></tr></thead><tbody>
<tr><td><strong>RED</strong></td><td>Wrote 21 failing tests defining exact behavior</td></tr>
<tr><td><strong>GREEN</strong></td><td>Implemented minimal code to pass each test</td></tr>
<tr><td><strong>REFACTOR</strong></td><td>Added property tests, edge cases, formatting</td></tr>
</tbody></table>
</div>
<p>Toyota Way benefits achieved:</p>
<ul>
<li><strong>Muda</strong> (無駄): 10-50x faster startup with persisted models</li>
<li><strong>Kaizen</strong> (改善): Standardized preprocessing pipeline</li>
<li><strong>Poka-yoke</strong> (ポカヨケ): Type-safe <code>Result&lt;T&gt;</code> APIs prevent misuse</li>
</ul>
<h2 id="related-chapters"><a class="header" href="#related-chapters">Related Chapters</a></h2>
<ul>
<li><a href="./machine-learning.html">Machine Learning</a> - KMeans clustering basics</li>
<li><a href="./anomaly-detection.html">Anomaly Detection</a> - Real-time monitoring</li>
<li><a href="../contributing/extreme-tdd.html">EXTREME TDD</a> - Methodology guide</li>
<li><a href="../contributing/toyota-way.html">Toyota Way Principles</a> - Design philosophy</li>
</ul>
<h2 id="future-hugging-face-hub-integration"><a class="header" href="#future-hugging-face-hub-integration">Future: Hugging Face Hub Integration</a></h2>
<blockquote>
<p><strong>Tracked:</strong> <a href="https://github.com/paiml/aprender/issues/100">aprender#100</a></p>
</blockquote>
<p>Once aprender adds HF Hub support, renacer will enable:</p>
<pre><code class="language-bash"># Push model to Hugging Face Hub
renacer --push-model hub:paiml/syscall-anomaly -- cargo build

# Load model from Hugging Face Hub
renacer --load-model hub:paiml/syscall-anomaly -- cargo build
</code></pre>
<p>Model cards will be auto-generated with training metadata, hyperparameters, and metrics.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../advanced/machine-learning.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../advanced/opentelemetry.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../advanced/machine-learning.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../advanced/opentelemetry.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../editor.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
